{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Directional-synthetic-Used-in-Paper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pSe6l6orkhN"
      },
      "source": [
        "pip install similaritymeasures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKFMrU2LrmXb"
      },
      "source": [
        "pip install tslearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9dDMD8gFIasP"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from scipy import linalg as LA\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import similaritymeasures\n",
        "import tslearn\n",
        "from tslearn.metrics import dtw\n",
        "from google.colab import files\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJyaGWNtIasV"
      },
      "source": [
        "# Generating Trajectories (50-50 by reversed direction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5H2P0zXIasc"
      },
      "source": [
        "# Generating Trajectories "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIssfwHOVR2P"
      },
      "source": [
        "# Data that we've used below is this one\n",
        "n = 100\n",
        "B = [0] * (2*n)\n",
        "\n",
        "for i in range(n):\n",
        "    B[i] = [[random.uniform(-1,1), random.uniform(-1, 1)]]\n",
        "    \n",
        "for i in range(n):\n",
        "    for j in range(49):\n",
        "        B[i].append([random.uniform(j,j+1), random.uniform(0, 5)])\n",
        "    for j in range(49,n-2):\n",
        "        B[i].append([random.uniform(n-j-3,n-j-2), random.uniform(-5, 0)])\n",
        "    B[i].append([random.uniform(-1,1), random.uniform(-1, 1)])\n",
        "    B[i] = np.array(B[i])\n",
        "    \n",
        "for i in range(n, 2*n):\n",
        "    B[i] = [[random.uniform(-1,1), random.uniform(-1, 1)]]\n",
        "    \n",
        "for i in range(n, 2*n):\n",
        "    for j in range(49):\n",
        "        B[i].append([random.uniform(j,j+1), random.uniform(-5, 0)])\n",
        "    for j in range(49,n-2):\n",
        "        B[i].append([random.uniform(n-j-3,n-j-2), random.uniform(5, 0)])\n",
        "    B[i].append([random.uniform(-1,1), random.uniform(-1, 1)])\n",
        "    B[i] = np.array(B[i])\n",
        "    \n",
        "B = np.array(B)\n",
        "data = B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjR4uzv2zDbd"
      },
      "source": [
        "#for i in range(2):\n",
        "#  np.savetxt('data[i].csv', data[i], delimiter=',') # i should be appeard on the name of csv files\n",
        "#  files.download('data[i].csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJX9YOxuIase"
      },
      "source": [
        "# Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-SSZm4OIasf"
      },
      "source": [
        "def fun(x):\n",
        "    if x >= 1: \n",
        "        y = 0\n",
        "    elif x <= -1:\n",
        "        y = math.pi\n",
        "    else: \n",
        "        y = np.arccos(x)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sksmK5dYIash"
      },
      "source": [
        "def dist_signed_point_closed(Q, gamma, sigma): \n",
        "    \n",
        "    p1 = gamma[:-1]\n",
        "    p2 = gamma[1:]\n",
        "    L = np.sqrt(((p2-p1)*(p2-p1)).sum(axis =1)) + 10e-6\n",
        "    \n",
        "    w = (p1-p2)*(-1,1)/(L * np.ones((2,1))).T\n",
        "    w[:,[0, 1]] = w[:,[1, 0]]\n",
        "    \n",
        "# signed distance to the extended lines of segments\n",
        "    dist_signed = np.sum(w * (Q.reshape(len(Q),1,2) - p1), axis=2)\n",
        "    x = abs(dist_signed.copy())\n",
        "    R = (L**2).reshape(-1,1)\n",
        "# u = argmin points on the extended lines of segments\n",
        "    u = p1 + ((((np.sum(((Q.reshape(len(Q),1,2) - p1) * (p2 - p1)),axis=2).reshape(len(Q)\n",
        "                ,-1,1,1) * (p2-p1).reshape(len(p2-p1),1,2))).reshape(len(Q),len(p1),2))/R)\n",
        "\n",
        "    G = np.sqrt(np.sum((u-p1)*(u-p1), axis=2))\n",
        "    H = np.sqrt(np.sum((u-p2)*(u-p2), axis=2))\n",
        "# d1 = distance to start points\n",
        "    d1 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p1)*(Q.reshape(len(Q),1,2)-p1), axis=2))\n",
        "# d2 = distance to end points\n",
        "    d2 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p2)*(Q.reshape(len(Q),1,2)-p2), axis=2))\n",
        "    d = np.where(d1 < d2, d1, d2)\n",
        "    dist_segment = np.where(abs(G + H - L) < np.ones(len(L)) * (10e-6), dist_signed, d)\n",
        "    \n",
        "    J2 = [0] * len(Q)\n",
        "    for i in range(len(Q)): \n",
        "        J2[i] = np.where(abs(G + H - L)[i] > 10e-6)[0]\n",
        "    J2 = np.array(J2)\n",
        "\n",
        "    dist_segment_copy = dist_segment.copy()\n",
        "    dist = abs(dist_segment_copy)\n",
        "\n",
        "\n",
        "    j = np.argmin(dist, axis =1)\n",
        "\n",
        "    sign = np.ones(len(Q))\n",
        "    for k in range(len(Q)): \n",
        "        if j[k] in J2[k]:\n",
        "            if j[k] == 0 and LA.norm(Q[k] - gamma[0]) < LA.norm(Q[k] - gamma[1]):\n",
        "                \n",
        "                y = LA.norm(gamma[0]-gamma[1]) - LA.norm(gamma[-1] - gamma[-2])\n",
        "                if y < 0:\n",
        "                    x = gamma[0] + 0.1 * LA.norm(gamma[0]-gamma[1])*(gamma[-2]-gamma[-1])/LA.norm(gamma[-2]-gamma[-1])\n",
        "                    z = gamma[0] + 0.1 * LA.norm(gamma[0]-gamma[1])*(gamma[1]-gamma[0])/LA.norm(gamma[1]-gamma[0])\n",
        "                    q = 2 * gamma[0] - (x + z)/2\n",
        "                else: \n",
        "                    x = gamma[0] + 0.1 * LA.norm(gamma[-1]-gamma[-2])*(gamma[1]-gamma[0])\n",
        "                    z = gamma[0] + 0.1 * LA.norm(gamma[-1]-gamma[-2])*(gamma[-2]-gamma[-1])\n",
        "                    q = 2 * gamma[0] - (x + z)/2\n",
        "                sign[k] = np.sign((q-gamma[-1]).dot(w[-1] + w[0]))\n",
        "                \n",
        "            elif j[k] == len(gamma)-2 and LA.norm(Q[k] - gamma[-1]) < LA.norm(Q[k] - gamma[-2]):\n",
        "                s = w[-1].dot((Q[k] - gamma[-1])/ LA.norm(Q[k] - gamma[-1]) + 10e-6)\n",
        "                sign[k] = np.sign(s)\n",
        "            \n",
        "            elif LA.norm(Q[k] - gamma[j[k]]) < LA.norm(Q[k] - gamma[j[k]+1]):  \n",
        "                q = 2 * gamma[j[k]] - (gamma[j[k]-1] + gamma[j[k]+1])/2\n",
        "                sign[k] = np.sign((q-gamma[j[k]]).dot(w[j[k]-1] + w[j[k]]))\n",
        "                    \n",
        "            elif LA.norm(Q[k] - gamma[j[k]+1]) <= LA.norm(Q[k] - gamma[j[k]]):\n",
        "                q = 2 * gamma[j[k]+1] - (gamma[j[k]] + gamma[j[k]+2])/2\n",
        "                sign[k] = np.sign((q-gamma[j[k]+1]).dot(w[j[k]] + w[j[k]+1]))\n",
        "\n",
        "    E = dist_segment[np.arange(len(dist_segment)),j] \n",
        "    F = dist[np.arange(len(dist)),j] \n",
        "    dist_weighted = sign * (1/sigma) * (E.reshape(-1,1) * np.exp(-(F/sigma)**2).reshape(-1,1)).reshape(1,-1)\n",
        "\n",
        "    return dist_weighted.reshape(len(Q))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ET2GWONIasj"
      },
      "source": [
        "def dist_signed_point_unclosed(Q, gamma, sigma): \n",
        "    \n",
        "    p1 = gamma[:-1]\n",
        "    p2 = gamma[1:]\n",
        "    L = np.sqrt(((p2-p1)*(p2-p1)).sum(axis =1)) + 10e-6\n",
        "    w = (p1-p2)*(-1,1)/(L * np.ones((2,1))).T\n",
        "    w[:,[0, 1]] = w[:,[1, 0]]\n",
        "    \n",
        "# signed distance to the extended lines of segments\n",
        "    dist_signed = np.sum(w * (Q.reshape(len(Q),1,2) - p1), axis=2)\n",
        "    x = abs(dist_signed.copy())\n",
        "    R = (L**2).reshape(-1,1)\n",
        "# u = argmin points on the extended lines of segments\n",
        "    u = p1 + ((((np.sum(((Q.reshape(len(Q),1,2) - p1) * (p2 - p1)),axis=2).reshape(len(Q)\n",
        "                ,-1,1,1) * (p2-p1).reshape(len(p2-p1),1,2))).reshape(len(Q),len(p1),2))/R)\n",
        "\n",
        "    G = np.sqrt(np.sum((u-p1)*(u-p1), axis=2))\n",
        "    H = np.sqrt(np.sum((u-p2)*(u-p2), axis=2))\n",
        "# d1 = distance to start points\n",
        "    d1 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p1)*(Q.reshape(len(Q),1,2)-p1), axis=2))\n",
        "# d2 = distance to end points\n",
        "    d2 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p2)*(Q.reshape(len(Q),1,2)-p2), axis=2))\n",
        "    d = np.where(d1 < d2, d1, d2)\n",
        "    dist_segment = np.where(abs(G + H - L) < np.ones(len(L)) * (10e-6), dist_signed, d)\n",
        "    \n",
        "    J2 = [0] * len(Q)\n",
        "    for i in range(len(Q)): \n",
        "        J2[i] = np.where(abs(G + H - L)[i] > 10e-6)[0]\n",
        "    J2 = np.array(J2)\n",
        "\n",
        "    dist_segment_copy = dist_segment.copy()\n",
        "    dist = abs(dist_segment_copy)\n",
        "    \n",
        "    dist_from_start_1 = np.sqrt(((Q -p1[0])*(Q -p1[0])).sum(axis =1))\n",
        "    ds_1 = ((Q -p1[0])*w[0]).sum(axis =1)\n",
        "    dist_from_start = ds_1 * np.maximum(abs(ds_1), np.sqrt(dist_from_start_1**2 - ds_1**2 + 10e-6))/ (dist_from_start_1 + 10e-6)\n",
        "\n",
        "\n",
        "    dist_from_end_1 = np.sqrt(((Q -p2[-1])*(Q -p2[-1])).sum(axis =1))\n",
        "    de_1 = ((Q -p2[-1])* w[-1]).sum(axis =1)\n",
        "    dist_from_end = de_1 * np.maximum(abs(de_1), np.sqrt(dist_from_end_1**2 - de_1**2 + 10e-6))/ (dist_from_end_1+ 10e-6)\n",
        "\n",
        "    dist_segment[:,0] = np.where(abs(dist[:,0]- dist_from_start_1)< 10e-8, dist_from_start, dist_segment[:,0]) \n",
        "    dist_segment[:,-1] = np.where(abs(dist[:,-1]- dist_from_end_1)< 10e-8, dist_from_end, dist_segment[:,-1]) \n",
        "\n",
        "\n",
        "    j = np.argmin(dist, axis =1)\n",
        "\n",
        "    sign = np.ones(len(Q))\n",
        "    for k in range(len(Q)): \n",
        "        if j[k] in J2[k]: \n",
        "            if j[k] == 0 and LA.norm(Q[k] - gamma[0]) < LA.norm(Q[k] - gamma[1]):\n",
        "                sign[k] = 1\n",
        "                \n",
        "            elif j[k] == len(gamma)-2 and LA.norm(Q[k] - gamma[j[k]+1]) < LA.norm(Q[k] - gamma[j[k]]):\n",
        "                sign[k] = 1\n",
        "            \n",
        "            elif LA.norm(Q[k] - gamma[j[k]]) < LA.norm(Q[k] - gamma[j[k]+1]):  \n",
        "                q = 2 * gamma[j[k]] - (gamma[j[k]-1] + gamma[j[k]+1])/2\n",
        "                sign[k] = np.sign((q-gamma[j[k]]).dot(w[j[k]-1] + w[j[k]]))\n",
        "                    \n",
        "            elif LA.norm(Q[k] - gamma[j[k]+1]) <= LA.norm(Q[k] - gamma[j[k]]) and j[k]+2 <=len(gamma)-1:\n",
        "                q = 2 * gamma[j[k]+1] - (gamma[j[k]] + gamma[j[k]+2])/2\n",
        "                sign[k] = np.sign((q-gamma[j[k]+1]).dot(w[j[k]] + w[j[k]+1]))\n",
        "\n",
        "    E = dist_segment[np.arange(len(dist_segment)),j] \n",
        "    F = dist[np.arange(len(dist)),j] \n",
        "    dist_weighted = sign * (1/sigma) * (E.reshape(-1,1) * np.exp(-(F/sigma)**2).reshape(-1,1)).reshape(1,-1)\n",
        "\n",
        "    return dist_weighted.reshape(len(Q))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjO8N8nDIasl"
      },
      "source": [
        "def dist_signed_point(Q, gamma, sigma):\n",
        "    if LA.norm(gamma[0]-gamma[-1]) > 10e-6:\n",
        "        A = dist_signed_point_unclosed(Q, gamma, sigma)\n",
        "    else: \n",
        "        A = dist_signed_point_closed(Q, gamma, sigma)\n",
        "        \n",
        "    return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOMbqvSxTD_o"
      },
      "source": [
        "# Choosing $Q$ and $\\sigma$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0JV-Z1Iasn"
      },
      "source": [
        "m = 20\n",
        "Q = np.ones((m,2))\n",
        "\n",
        "for i in range(m):\n",
        "    Q[i] = (random.uniform(-1, 51), random.uniform(-8, 8)) \n",
        "np.savetxt('Q.csv', Q, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T99comZtng82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3c068031-42a3-431e-abbb-6928b6eaec5b"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('Q.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b61447cd-29e7-4862-8e1f-5b57e11dfa87\", \"Q.csv\", 10092)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84B3gWdOIasp"
      },
      "source": [
        "sigma = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVMcqbwqTPvL"
      },
      "source": [
        "#Mapping to $\\mathbb{R}^m$ under $v_Q^{\\sigma}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcT6zFv8Iasr"
      },
      "source": [
        "projected_go = [0] * n\n",
        "projected_back = [0] * n\n",
        "\n",
        "for i in range(n):\n",
        "    projected_go[i] = np.concatenate((dist_signed_point(Q,data[i],sigma),[1]), axis = 0)\n",
        "\n",
        "for i in range(n):\n",
        "    projected_back[i] = np.concatenate((dist_signed_point(Q,data[n+i],sigma),[-1]), axis = 0)\n",
        "    \n",
        "projected_go = np.array(projected_go)\n",
        "projected_back = np.array(projected_back)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fxqqDNwoaDq"
      },
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr_2FGfNN8aR"
      },
      "source": [
        "clf0 = KNeighborsClassifier(n_neighbors=5) \n",
        "clf1 = svm.SVC(kernel='linear') \n",
        "clf2 = make_pipeline(StandardScaler(), svm.SVC(C= 20000, kernel = 'rbf', gamma= 'auto', max_iter = 200000))\n",
        "clf3 = make_pipeline(StandardScaler(), svm.SVC(C= 10000, kernel = 'rbf', gamma= 'auto', max_iter = 200000))\n",
        "clf4 = make_pipeline(StandardScaler(), svm.SVC(C= 15000, kernel = 'rbf', gamma= 'auto', max_iter = 200000))\n",
        "clf5 = make_pipeline(StandardScaler(), svm.SVC(C=100, kernel = 'poly', degree =3, max_iter = 400000))\n",
        "clf6 = make_pipeline(StandardScaler(), svm.SVC(C=10000, kernel = 'poly', degree =2, max_iter = 400000))\n",
        "clf7 = DecisionTreeClassifier()\n",
        "clf8 = DecisionTreeClassifier(max_depth= 4)\n",
        "clf9 = DecisionTreeClassifier(max_depth= 5)\n",
        "clf10 = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "clf11 = RandomForestClassifier(n_estimators=100, max_depth=6)\n",
        "clf12 = RandomForestClassifier(n_estimators=100, max_depth=7)\n",
        "clf13 = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=5)\n",
        "clf14 = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=6)\n",
        "clf15 = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=7)\n",
        "clf16 = AdaBoostClassifier(n_estimators= 100,learning_rate=0.95)\n",
        "clf17 = AdaBoostClassifier(n_estimators= 100,learning_rate=1.05)\n",
        "\n",
        "clf = [clf0,clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11,clf12,clf13,clf14,clf15,clf16,clf17]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xsgfs_5LfQd"
      },
      "source": [
        "# Classification after using our feature map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyoLzvQiBkS6"
      },
      "source": [
        "X_1 = projected_go\n",
        "X_2 = projected_back"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9FFJRBOIasw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafc02bd-9695-45d3-bcb5-984e8588069b"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "t = 1000\n",
        "\n",
        "error_train = np.zeros((len(clf), t))\n",
        "error_test = np.zeros((len(clf), t))\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(n), 30)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(n)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(n), 30)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(n)) - set(S)))\n",
        "    \n",
        "    data_train = np.insert(X_1[R_c], len(X_1[R_c]), X_2[S_c], axis = 0)\n",
        "    data_test = np.insert(X_1[R], len(X_1[R]), X_2[S], axis = 0)\n",
        "    \n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "    \n",
        "    for k in range(len(clf)):\n",
        "        \n",
        "        model = clf[k]\n",
        "        #Train the model using the training sets\n",
        "        model.fit(data_train[:,:-1], data_train[:,-1])\n",
        "\n",
        "        #Predict the response for test dataset\n",
        "        y_pred = model.predict(data_test[:,:-1])\n",
        "        error_test[k][i] = 1 - metrics.accuracy_score(data_test[:,-1], y_pred)\n",
        "        \n",
        "        x_pred = model.predict(data_train[:,:-1])\n",
        "        error_train[k][i] = 1 - metrics.accuracy_score(data_train[:,-1], x_pred)\n",
        "        \n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 91.2971339225769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "aWKtMW8tQ8NY",
        "outputId": "50ce2d9a-1fa9-4868-9033-aeb245a53576"
      },
      "source": [
        "print('|Q|=20', 'sigma=', sigma, ', t=', t, ',data = B')\n",
        "\n",
        "Dic1 = {}\n",
        "\n",
        "models = [\"KNN\", \"Linear kernel SVM\", \"Gaussian SVM, C=1, gamma= auto\", \n",
        "          \"Gaussian SVM, C = 10, gamma = auto\", \"Gaussian SVM, C = 100, gamma = auto\",\n",
        "          \"Poly kernel SVM, deg=3\", \"Poly kernel SVM, deg=2, C=100\", \n",
        "          \"Decision Tree\", \"Decision Tree, depth=3\", \"Decision Tree, depth=4\",\n",
        "          'RF, gini, max_depth=5, 100 estimators',\n",
        "          'RF, gini, max_depth=6, 100 estimators',\n",
        "          'RF, gini, max_depth=7, 100 estimators', \n",
        "          'RF, entropy, max_depth=5, 100 estimators',\n",
        "          'RF, entropy, max_depth=6, 100 estimators', \n",
        "          'RF, entropy, max_depth=7, 100 estimators', \n",
        "          'AdaBoost, learning rate=0.95, 100 estimators',\n",
        "          'AdaBoost, learning rate=1.05, 100 estimators']\n",
        "\n",
        "for k in range(len(models)): \n",
        "    Dic1[k+1] = [models[k], np.round(np.mean(error_train[k]), decimals = 4), \n",
        "                np.round(np.mean(error_test[k]), decimals = 4),\n",
        "               np.round(np.std(error_test[k]), decimals = 4)]\n",
        "    \n",
        "df2 = pd.DataFrame.from_dict(Dic1, orient='index', columns=['Classifier','Train Error', \n",
        "                                        'Test Error', 'Standard Deviation'])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=20 sigma= 5 , t= 100 ,data = B\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Standard Deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear kernel SVM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gaussian SVM, C=1, gamma= auto</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gaussian SVM, C = 10, gamma = auto</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gaussian SVM, C = 100, gamma = auto</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Poly kernel SVM, deg=3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Poly kernel SVM, deg=2, C=100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4820</td>\n",
              "      <td>0.0638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Decision Tree, depth=3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>0.0065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Decision Tree, depth=4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RF, gini, max_depth=5, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RF, gini, max_depth=6, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RF, gini, max_depth=7, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RF, entropy, max_depth=5, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RF, entropy, max_depth=6, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RF, entropy, max_depth=7, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AdaBoost, learning rate=0.95, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>AdaBoost, learning rate=1.05, 100 estimators</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Classifier  ...  Standard Deviation\n",
              "1                                            KNN  ...              0.0000\n",
              "2                              Linear kernel SVM  ...              0.0000\n",
              "3                 Gaussian SVM, C=1, gamma= auto  ...              0.0000\n",
              "4             Gaussian SVM, C = 10, gamma = auto  ...              0.0000\n",
              "5            Gaussian SVM, C = 100, gamma = auto  ...              0.0000\n",
              "6                         Poly kernel SVM, deg=3  ...              0.0000\n",
              "7                  Poly kernel SVM, deg=2, C=100  ...              0.0638\n",
              "8                                  Decision Tree  ...              0.0067\n",
              "9                         Decision Tree, depth=3  ...              0.0065\n",
              "10                        Decision Tree, depth=4  ...              0.0069\n",
              "11         RF, gini, max_depth=5, 100 estimators  ...              0.0000\n",
              "12         RF, gini, max_depth=6, 100 estimators  ...              0.0000\n",
              "13         RF, gini, max_depth=7, 100 estimators  ...              0.0000\n",
              "14      RF, entropy, max_depth=5, 100 estimators  ...              0.0000\n",
              "15      RF, entropy, max_depth=6, 100 estimators  ...              0.0000\n",
              "16      RF, entropy, max_depth=7, 100 estimators  ...              0.0000\n",
              "17  AdaBoost, learning rate=0.95, 100 estimators  ...              0.0071\n",
              "18  AdaBoost, learning rate=1.05, 100 estimators  ...              0.0071\n",
              "\n",
              "[18 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cnqJQ4ZIas2"
      },
      "source": [
        "# Classification with old distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlzHNpS1Ias3"
      },
      "source": [
        "def old_dist(Q, gamma):\n",
        "    \n",
        "    p2 = gamma[1:]\n",
        "    p1 = gamma[:-1]\n",
        "    L = np.sqrt(((p2-p1)*(p2-p1)).sum(axis =1))\n",
        "    II = np.where(L>10e-8)[0]\n",
        "    L = L[II]\n",
        "    p1 = p1[II]\n",
        "    p2 = p2[II]\n",
        "    w = (p1-p2)*(-1,1)/(L*np.ones((2,1))).T\n",
        "    w[:,[0, 1]] = w[:,[1, 0]]\n",
        "    \n",
        "    dist_dot = np.sum(w * (Q.reshape(len(Q),1,2) - p1), axis=2)\n",
        "    \n",
        "    x = abs(dist_dot.copy())\n",
        "    R = (L**2).reshape(-1,1)\n",
        "    u = p1 + ((((np.sum(((Q.reshape(len(Q),1,2) - p1) * (p2 - p1)),axis=2).reshape(len(Q)\n",
        "                ,-1,1,1) * (p2-p1).reshape(len(p2-p1),1,2))).reshape(len(Q),len(p1),2))/R)\n",
        "    \n",
        "    G = np.sqrt(np.sum((u-p1)*(u-p1), axis=2))\n",
        "    H = np.sqrt(np.sum((u-p2)*(u-p2), axis=2))\n",
        "    d1 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p1)*(Q.reshape(len(Q),1,2)-p1), axis=2))\n",
        "    d2 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p2)*(Q.reshape(len(Q),1,2)-p2), axis=2))\n",
        "\n",
        "    dist = np.where(abs(G + H - L) < np.ones(len(L)) * (10e-8), x, np.minimum(d1, d2))\n",
        "\n",
        "    j = np.argmin(dist, axis =1)\n",
        "    dist_weighted = dist[np.arange(len(dist)),j]\n",
        "    \n",
        "    return dist_weighted.reshape(len(Q)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB745HJCIas5"
      },
      "source": [
        "proj_go = [0] * n\n",
        "proj_back = [0] * n\n",
        "\n",
        "for i in range(n):\n",
        "    proj_go[i] = np.concatenate((old_dist(Q,data[i]),[1]), axis = 0)\n",
        "\n",
        "for i in range(n):\n",
        "    proj_back[i] = np.concatenate((old_dist(Q,data[n+i]),[-1]), axis = 0)\n",
        "    \n",
        "proj_go = np.array(proj_go)\n",
        "proj_back = np.array(proj_back)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku6uDGRXFVhr"
      },
      "source": [
        "#Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvjN1XBuGIC7"
      },
      "source": [
        "X_1 = proj_go\n",
        "X_2 = proj_back"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fjIGy0DVIas9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d360e8-2897-413b-d8be-2e70c252ed86"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "t = 1000\n",
        "\n",
        "error_train_list = np.zeros((len(clf), t))\n",
        "error_test_list = np.zeros((len(clf), t))\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(n), 30)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(n)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(n), 30)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(n)) - set(S)))\n",
        "    \n",
        "    data_train = np.insert(X_1[R_c], len(X_1[R_c]), X_2[S_c], axis = 0)\n",
        "    data_test = np.insert(X_1[R], len(X_1[R]), X_2[S], axis = 0)\n",
        "    \n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "    \n",
        "    for k in range(len(clf)):\n",
        "        \n",
        "        model = clf[k]\n",
        "        #Train the model using the training sets\n",
        "        model.fit(data_train[:,:-1], data_train[:,-1])\n",
        "\n",
        "        #Predict the response for test dataset\n",
        "        y_pred = model.predict(data_test[:,:-1])\n",
        "        error_test_list[k][i] = 1 - metrics.accuracy_score(data_test[:,-1], y_pred)\n",
        "        \n",
        "        x_pred = model.predict(data_train[:,:-1])\n",
        "        error_train_list[k][i] = 1 - metrics.accuracy_score(data_train[:,-1], x_pred)\n",
        "        \n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 140.78698921203613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mTBDehDRfbb",
        "outputId": "b53acc96-b7b0-49a5-bc32-d4e0eae5f97c"
      },
      "source": [
        "print('|Q|=20,', ' t=', t, ',data = B,', 'Old Distance')\n",
        "\n",
        "Dic2 = {}\n",
        "\n",
        "models = [\"KNN\", \"Linear kernel SVM\", \"Gaussian SVM, C=1, gamma= auto\", \n",
        "          \"Gaussian SVM, C = 10, gamma = auto\", \"Gaussian SVM, C = 100, gamma = auto\",\n",
        "          \"Poly kernel SVM, deg=3\", \"Poly kernel SVM, deg=2, C=100\", \n",
        "          \"Decision Tree\", \"Decision Tree, depth=3\", \"Decision Tree, depth=4\",\n",
        "          'RF, gini, max_depth=5, 100 estimators',\n",
        "          'RF, gini, max_depth=6, 100 estimators',\n",
        "          'RF, gini, max_depth=7, 100 estimators', \n",
        "          'RF, entropy, max_depth=5, 100 estimators',\n",
        "          'RF, entropy, max_depth=6, 100 estimators', \n",
        "          'RF, entropy, max_depth=7, 100 estimators', \n",
        "          'AdaBoost, learning rate=0.95, 100 estimators',\n",
        "          'AdaBoost, learning rate=1.05, 100 estimators']\n",
        "\n",
        "for k in range(len(models)): \n",
        "    Dic2[k+1] = [models[k], np.round(np.mean(error_train_list[k]), decimals = 4), \n",
        "                np.round(np.mean(error_test_list[k]), decimals = 4),\n",
        "               np.round(np.std(error_test_list[k]), decimals = 4)]\n",
        "    \n",
        "df2 = pd.DataFrame.from_dict(Dic2, orient='index', columns=['Classifier','Train Error', \n",
        "                                        'Test Error', 'Standard Deviation'])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=20,  t= 100 ,data = B, Old Distance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Standard Deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.3076</td>\n",
              "      <td>0.5132</td>\n",
              "      <td>0.0503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear kernel SVM</td>\n",
              "      <td>0.3512</td>\n",
              "      <td>0.5337</td>\n",
              "      <td>0.0542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gaussian SVM, C=1, gamma= auto</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4690</td>\n",
              "      <td>0.0561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gaussian SVM, C = 10, gamma = auto</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4690</td>\n",
              "      <td>0.0561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gaussian SVM, C = 100, gamma = auto</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4690</td>\n",
              "      <td>0.0561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Poly kernel SVM, deg=3</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5285</td>\n",
              "      <td>0.0541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Poly kernel SVM, deg=2, C=100</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>0.0615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Decision Tree, depth=3</td>\n",
              "      <td>0.1899</td>\n",
              "      <td>0.5058</td>\n",
              "      <td>0.0592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Decision Tree, depth=4</td>\n",
              "      <td>0.1220</td>\n",
              "      <td>0.4887</td>\n",
              "      <td>0.0643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RF, gini, max_depth=5, 100 estimators</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.5083</td>\n",
              "      <td>0.0612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RF, gini, max_depth=6, 100 estimators</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.5087</td>\n",
              "      <td>0.0589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RF, gini, max_depth=7, 100 estimators</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5112</td>\n",
              "      <td>0.0613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RF, entropy, max_depth=5, 100 estimators</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.5175</td>\n",
              "      <td>0.0490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RF, entropy, max_depth=6, 100 estimators</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.5218</td>\n",
              "      <td>0.0635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RF, entropy, max_depth=7, 100 estimators</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.0614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AdaBoost, learning rate=0.95, 100 estimators</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4825</td>\n",
              "      <td>0.0620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>AdaBoost, learning rate=1.05, 100 estimators</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4837</td>\n",
              "      <td>0.0615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Classifier  ...  Standard Deviation\n",
              "1                                            KNN  ...              0.0503\n",
              "2                              Linear kernel SVM  ...              0.0542\n",
              "3                 Gaussian SVM, C=1, gamma= auto  ...              0.0561\n",
              "4             Gaussian SVM, C = 10, gamma = auto  ...              0.0561\n",
              "5            Gaussian SVM, C = 100, gamma = auto  ...              0.0561\n",
              "6                         Poly kernel SVM, deg=3  ...              0.0541\n",
              "7                  Poly kernel SVM, deg=2, C=100  ...              0.0518\n",
              "8                                  Decision Tree  ...              0.0615\n",
              "9                         Decision Tree, depth=3  ...              0.0592\n",
              "10                        Decision Tree, depth=4  ...              0.0643\n",
              "11         RF, gini, max_depth=5, 100 estimators  ...              0.0612\n",
              "12         RF, gini, max_depth=6, 100 estimators  ...              0.0589\n",
              "13         RF, gini, max_depth=7, 100 estimators  ...              0.0613\n",
              "14      RF, entropy, max_depth=5, 100 estimators  ...              0.0490\n",
              "15      RF, entropy, max_depth=6, 100 estimators  ...              0.0635\n",
              "16      RF, entropy, max_depth=7, 100 estimators  ...              0.0614\n",
              "17  AdaBoost, learning rate=0.95, 100 estimators  ...              0.0620\n",
              "18  AdaBoost, learning rate=1.05, 100 estimators  ...              0.0615\n",
              "\n",
              "[18 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CSA2MGwIatB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fe767224-9d63-4c0e-d4c0-96986106f7c0"
      },
      "source": [
        "E3 = df3.to_latex(index=False)\n",
        "np.savetxt('Old_feature_map_classification_results.tex', [E3], fmt='%s')\n",
        "files.download('Old_feature_map_classification_results.tex')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_451e630c-9756-42c0-8dab-c64c86944c27\", \"Old_feature_map_classification_results.tex\", 779)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5DkOr1Nm9EQ"
      },
      "source": [
        "# Classification based on endpoints (Not appeared on the paper)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH_iYlHsbxIl"
      },
      "source": [
        "for i in range(n, 2*n):\n",
        "  C[i] = list(data[i][[0,-1]].reshape(4,)) + [-1]\n",
        "\n",
        "data_endpoints = C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiXAO8q0bY3s"
      },
      "source": [
        "endpoints_go = data_endpoints[:100]\n",
        "endpoints_back = data_endpoints[100:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBRjcbJLm6BG",
        "outputId": "8828de47-2f5b-4d45-c012-badd1b71708d"
      },
      "source": [
        "C = np.zeros((2*n, 5))\n",
        "\n",
        "for i in range(n):\n",
        "  C[i] = list(data[i][[0,-1]].reshape(4,)) + [1]\n",
        "Start_time = time.time()\n",
        "\n",
        "t = 1000\n",
        "\n",
        "error_train = np.zeros((len(clf), t))\n",
        "error_test = np.zeros((len(clf), t))\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(n), 30)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(n)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(n), 30)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(n)) - set(S)))\n",
        "    \n",
        "    data_train = np.insert(endpoints_go[R_c], len(endpoints_go[R_c]), endpoints_back[S_c], axis = 0)\n",
        "    data_test = np.insert(endpoints_go[R], len(endpoints_go[R]), endpoints_back[S], axis = 0)\n",
        "    \n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "    \n",
        "    for k in range(len(clf)):\n",
        "        \n",
        "        model = clf[k]\n",
        "        #Train the model using the training sets\n",
        "        model.fit(data_train[:,:-1], data_train[:,-1])\n",
        "\n",
        "        #Predict the response for test dataset\n",
        "        y_pred = model.predict(data_test[:,:-1])\n",
        "        error_test[k][i] = 1 - metrics.accuracy_score(data_test[:,-1], y_pred)\n",
        "        \n",
        "        x_pred = model.predict(data_train[:,:-1])\n",
        "        error_train[k][i] = 1 - metrics.accuracy_score(data_train[:,-1], x_pred)\n",
        "        \n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 325.7384831905365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "v4ZWH2ylnGCk",
        "outputId": "a2be7412-e59a-4756-9dc4-5e0370fb6506"
      },
      "source": [
        "print('Classification by endpoints', '|Q|=200', 'sigma=', sigma, ', t=1000,', 'data = B')\n",
        "\n",
        "Dic1 = {}\n",
        "\n",
        "models = [\"Linear SVM\", \"Gaussian kernel SVM\", \"C=100, Gaussian kernel SVM\", \n",
        "          \"SVM, poly, deg=auto\", \"Decision Tree\", \n",
        "          \"RandomForest with 100 estimators\", \"AdaBoost with 100 estimators, r=1\"]\n",
        "\n",
        "for k in range(len(models)): \n",
        "    Dic1[k+1] = [models[k], np.round(np.mean(error_train[k]), decimals = 4), \n",
        "                np.round(np.mean(error_test[k]), decimals = 4),\n",
        "                #np.round(np.median(error_test[k]), decimals = 4),\n",
        "               np.round(np.std(error_test[k]), decimals = 4)]\n",
        "    \n",
        "df1 = pd.DataFrame.from_dict(Dic1, orient='index', columns=['Classifier',\n",
        "          'Train Error', 'Test Error', 'Standard Deviation'])\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification by endpoints |Q|=200 sigma= 5 , t=1000, data = B\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Standard Deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Linear SVM</td>\n",
              "      <td>0.4283</td>\n",
              "      <td>0.4868</td>\n",
              "      <td>0.0578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gaussian kernel SVM</td>\n",
              "      <td>0.2845</td>\n",
              "      <td>0.4546</td>\n",
              "      <td>0.0541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C=100, Gaussian kernel SVM</td>\n",
              "      <td>0.0786</td>\n",
              "      <td>0.4847</td>\n",
              "      <td>0.0566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM, poly, deg=auto</td>\n",
              "      <td>0.3350</td>\n",
              "      <td>0.4607</td>\n",
              "      <td>0.0559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4935</td>\n",
              "      <td>0.0616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForest with 100 estimators</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4782</td>\n",
              "      <td>0.0592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost with 100 estimators, r=1</td>\n",
              "      <td>0.0258</td>\n",
              "      <td>0.4926</td>\n",
              "      <td>0.0573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Classifier  ...  Standard Deviation\n",
              "1                         Linear SVM  ...              0.0578\n",
              "2                Gaussian kernel SVM  ...              0.0541\n",
              "3         C=100, Gaussian kernel SVM  ...              0.0566\n",
              "4                SVM, poly, deg=auto  ...              0.0559\n",
              "5                      Decision Tree  ...              0.0616\n",
              "6   RandomForest with 100 estimators  ...              0.0592\n",
              "7  AdaBoost with 100 estimators, r=1  ...              0.0573\n",
              "\n",
              "[7 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mi3An65fnQ9T",
        "outputId": "a6c44c45-10cd-4206-b70d-18782cc45ec0"
      },
      "source": [
        "E1 = df1.to_latex(index=False)\n",
        "np.savetxt('Endpoints_classification_results.tex', [E1], fmt='%s')\n",
        "files.download('Endpoints_classification_results.tex')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_721fd0d9-93f8-4c88-b16b-51954fa6a8ea\", \"Endpoints_classification_results.tex\", 779)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQntkFEQIatD"
      },
      "source": [
        "# KNN with $d_Q^{\\sigma}$, $d_Q$, dtw, Frechet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqofsdg8IatE"
      },
      "source": [
        "## KNN with $d_Q^{\\sigma}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tca_rORYIatE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb5f558-dab4-4950-aed1-acc63470d867"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "t = 100\n",
        "\n",
        "error_train_d_Q_sigma = np.zeros(t)\n",
        "error_test_d_Q_sigma = np.zeros(t)\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(n), 30)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(n)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(n), 30)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(n)) - set(S)))\n",
        "    \n",
        "    data_train = np.insert(projected_go[R_c], len(projected_go[R_c]), projected_back[S_c], axis = 0)\n",
        "    data_test = np.insert(projected_go[R], len(projected_go[R]), projected_back[S], axis = 0)\n",
        "    \n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "    \n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "        #Train the model using the training sets\n",
        "    model.fit(data_train[:,:-1], data_train[:,-1])\n",
        "\n",
        "        #Predict the response for test dataset\n",
        "    y_pred = model.predict(data_test[:,:-1])\n",
        "    error_test_d_Q_sigma[i] = 1 - metrics.accuracy_score(data_test[:,-1], y_pred)\n",
        "        \n",
        "    x_pred = model.predict(data_train[:,:-1])\n",
        "    error_train_d_Q_sigma[i] = 1 - metrics.accuracy_score(data_train[:,-1], x_pred)\n",
        "        \n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 0.8445241451263428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj_7yefXIatG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9b1dde-aed8-4b94-d2e8-82ed0612e805"
      },
      "source": [
        "print(np.mean(error_train_d_Q_sigma), np.median(error_train_d_Q_sigma), np.std(error_train_d_Q_sigma))\n",
        "print(np.mean(error_test_d_Q_sigma),np.median(error_test_d_Q_sigma), np.std(error_test_d_Q_sigma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.0 0.0\n",
            "0.0 0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4TV-oAQIatI"
      },
      "source": [
        "# KNN with $d_Q$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgLZmfgCIatI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712b8c58-abe9-4ae7-bba9-1dcd5b4f30c6"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "t = 10\n",
        "\n",
        "error_train_d_Q = np.zeros(t)\n",
        "error_test_d_Q = np.zeros(t)\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(n), 30)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(n)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(n), 30)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(n)) - set(S)))\n",
        "    \n",
        "    data_train = np.insert(proj_go[R_c], len(proj_go[R_c]), proj_back[S_c], axis = 0)\n",
        "    data_test = np.insert(proj_go[R], len(proj_go[R]), proj_back[S], axis = 0)\n",
        "    \n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "    \n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "        #Train the model using the training sets\n",
        "    model.fit(data_train[:,:-1], data_train[:,-1])\n",
        "\n",
        "        #Predict the response for test dataset\n",
        "    y_pred = model.predict(data_test[:,:-1])\n",
        "    error_test_d_Q[i] = 1 - metrics.accuracy_score(data_test[:,-1], y_pred)\n",
        "        \n",
        "    x_pred = model.predict(data_train[:,:-1])\n",
        "    error_train_d_Q[i] = 1 - metrics.accuracy_score(data_train[:,-1], x_pred)\n",
        "        \n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 0.11089062690734863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Se8K_-IatL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10b649c-5a69-4d4c-914f-fb949117bc7f"
      },
      "source": [
        "print(np.mean(error_train_d_Q), np.median(error_train_d_Q), np.std(error_train_d_Q))\n",
        "print(np.mean(error_test_d_Q),np.median(error_test_d_Q), np.std(error_test_d_Q))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.28428571428571425 0.2857142857142857 0.02649605284427344\n",
            "0.465 0.4583333333333333 0.052413950645054636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXDvh84rIatN"
      },
      "source": [
        "# KNN with dtw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgy6ceL9IatN"
      },
      "source": [
        "def func1(a,b):\n",
        "    c = np.zeros(len(b))\n",
        "    for i in range(len(b)):\n",
        "        c[i] = tslearn.metrics.dtw(a,b[i])\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEmF7gfJIatO"
      },
      "source": [
        "A = data[:100]\n",
        "B = data[100:]\n",
        "E = [0] * len(A)\n",
        "F = [0] * len(B)\n",
        "\n",
        "for i in range(len(A)):\n",
        "    E[i] = np.concatenate((A[i],[[1,1]]), axis = 0)\n",
        "\n",
        "for i in range(len(B)):\n",
        "    F[i] = np.concatenate((B[i],[[-1,-1]]), axis = 0)\n",
        "    \n",
        "E = np.array(E)\n",
        "F = np.array(F)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq3mArNAIatQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd20942f-9dcd-4619-f788-56ccf17e97ea"
      },
      "source": [
        "Start_time = time.time()\n",
        "\n",
        "t = 10\n",
        "\n",
        "error_train_dtw = np.zeros(t)\n",
        "error_test_dtw = np.zeros(t)\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(n), 30)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(n)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(n), 30)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(n)) - set(S)))\n",
        "        \n",
        "    data_train = np.insert(E[R_c], len(E[R_c]), F[S_c], axis = 0)\n",
        "    data_test = np.insert(E[R], len(E[R]), F[S], axis = 0)\n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "    \n",
        "    D_train = np.zeros((len(data_train),len(data_train)))\n",
        "\n",
        "    for k in range(len(data_train)):\n",
        "        D_train[k] = func1(data_train[k,:-1], data_train[:,:-1])\n",
        "    \n",
        "    D_test = np.zeros((len(data_test),len(data_train))) \n",
        "    \n",
        "    for j in range(len(data_test)):\n",
        "        D_test[j] = func1(data_test[j,:-1], data_train[:,:-1])\n",
        "    \n",
        "    model = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n",
        "    #Train the model using the training sets\n",
        "\n",
        "    model.fit(D_train, data_train[:,-1][:,0])\n",
        "    \n",
        "    #Predict the response for test dataset\n",
        "    y_pred = model.predict(D_test)\n",
        "    error_test_dtw[i] = 1 - metrics.accuracy_score(data_test[:,-1][:,0], y_pred)\n",
        "    #error_test_dtw[i] = np.sum(abs(y_pred - data_test[:,-1][:,0]))/len(data_test)\n",
        "        \n",
        "    x_pred = model.predict(D_train)\n",
        "    error_train_dtw[i] = 1 - metrics.accuracy_score(data_train[:,-1][:,0], x_pred)\n",
        "\n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 123.83622694015503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNDIKqMUIatT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f4450a-1530-4527-a008-e80a902fbdfa"
      },
      "source": [
        "print(np.mean(error_train_dtw), np.median(error_train_dtw), np.std(error_train_dtw))\n",
        "print(np.mean(error_test_dtw),np.median(error_test_dtw), np.std(error_test_dtw))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.0 0.0\n",
            "0.0 0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h4BgaF5IatU"
      },
      "source": [
        "# KNN with Frechet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk0Jx4EGIatV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868f1e96-b2c4-4e58-d3ab-6fa87c927960"
      },
      "source": [
        "# run time is very high: I ran for 20 and 6 instead of 100 and 30\n",
        "Start_time = time.time()\n",
        "\n",
        "t = 1\n",
        "\n",
        "error_train_fr = np.zeros(t)\n",
        "error_test_fr = np.zeros(t)\n",
        "\n",
        "for i in range(t): \n",
        "\n",
        "    R1 = random.sample(range(20), 6)\n",
        "    R = np.sort(R1)\n",
        "    R_c = np.sort(list(set(range(20)) - set(R)))\n",
        "    \n",
        "    S1 = random.sample(range(20), 6)\n",
        "    S = np.sort(S1)\n",
        "    S_c = np.sort(list(set(range(20)) - set(S)))\n",
        "    \n",
        "    data_train = np.insert(E[R_c], len(E[R_c]), F[S_c], axis = 0)\n",
        "    data_test = np.insert(E[R], len(E[R]), F[S], axis = 0)\n",
        "    data_train = list(data_train)\n",
        "    data_test = list(data_test)\n",
        "    random.shuffle(data_train)\n",
        "    random.shuffle(data_test)\n",
        "    data_train = np.array(data_train)\n",
        "    data_test = np.array(data_test)\n",
        "\n",
        "    D_train = np.zeros((len(data_train),len(data_train)))\n",
        "\n",
        "    for k in range(len(data_train)-1):\n",
        "        for s in range(k+1, len(data_train)):\n",
        "            D_train[k][s] = similaritymeasures.frechet_dist(data_train[k,:-1], data_train[s,:-1])\n",
        "            D_train[s][k] = D_train[k][s]\n",
        "    \n",
        "    D_test = np.zeros((len(data_test),len(data_train))) \n",
        "    \n",
        "    for j in range(len(data_test)):\n",
        "        for u in range(len(data_train)):\n",
        "            D_test[j][u] = similaritymeasures.frechet_dist(data_test[j,:-1], data_train[u,:-1])\n",
        "    \n",
        "    model = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n",
        "    #Train the model using the training sets\n",
        "\n",
        "    model.fit(D_train, data_train[:,-1][:,0])\n",
        "    \n",
        "    #Predict the response for test dataset\n",
        "    y_pred = model.predict(D_test)\n",
        "    error_test_fr[i] = 1 - metrics.accuracy_score(data_test[:,-1][:,0], y_pred)\n",
        "        \n",
        "    x_pred = model.predict(D_train)\n",
        "    error_train_fr[i] = 1 - metrics.accuracy_score(data_train[:,-1][:,0], x_pred)\n",
        "        \n",
        "print('total time =', time.time() - Start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time = 98.74538397789001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9uZrnciIatW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3463ebd5-7435-4d90-f3ec-a1af2e730e5e"
      },
      "source": [
        "print(np.mean(error_train_fr), np.median(error_train_fr), np.std(error_train_fr))\n",
        "print(np.mean(error_test_fr), np.median(error_test_fr), np.std(error_test_fr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.0 0.0\n",
            "0.0 0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fCbBToQIatY"
      },
      "source": [
        "# Presenting results in a dataframe and Latex output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn3vGDIdIatY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "095eeabe-87f5-4689-ed45-591b3ebc0312"
      },
      "source": [
        "print('|Q|=20,', 't=10,', '|data|= 100 + 100= 200,', 'data = B')\n",
        "\n",
        "Dic3 = {}\n",
        "\n",
        "Dic3[1] = [\"$d_Q^{\\sigma}$ distance\", np.round(np.mean(error_train_d_Q_sigma), decimals = 4), \n",
        "                np.round(np.mean(error_test_d_Q_sigma), decimals = 4),\n",
        "                np.round(np.median(error_test_d_Q_sigma), decimals = 4),\n",
        "               np.round(np.std(error_test_d_Q_sigma), decimals = 4)]\n",
        "\n",
        "Dic3[2] = [\"DTW distance\", np.round(np.mean(error_train_dtw), decimals = 4), \n",
        "                np.round(np.mean(error_test_dtw), decimals = 4),\n",
        "                np.round(np.median(error_test_dtw), decimals = 4),\n",
        "               np.round(np.std(error_test_dtw), decimals = 4)]\n",
        "\n",
        "Dic3[3] = [\"Frechet distance\", np.round(np.mean(error_train_fr), decimals = 4), \n",
        "                np.round(np.mean(error_test_fr), decimals = 4),\n",
        "                np.round(np.median(error_test_fr), decimals = 4),\n",
        "               np.round(np.std(error_test_fr), decimals = 4)]\n",
        "\n",
        "\n",
        "Dic3[4] = [\"$d_Q$ distance\", np.round(np.mean(error_train_d_Q), decimals = 4), \n",
        "                np.round(np.mean(error_test_d_Q), decimals = 4),\n",
        "                np.round(np.median(error_test_d_Q), decimals = 4),\n",
        "               np.round(np.std(error_test_d_Q), decimals = 4)]\n",
        "\n",
        "df4 = pd.DataFrame.from_dict(Dic3, orient='index', columns=['Distance','Train Error', \n",
        "                                        'Test Error', 'Median Error', 'Standar Deviation'])\n",
        "df4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|Q|=20, t=10, |data|= 100 + 100= 200, data = B\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Distance</th>\n",
              "      <th>Train Error</th>\n",
              "      <th>Test Error</th>\n",
              "      <th>Median Error</th>\n",
              "      <th>Standar Deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$d_Q^{\\sigma}$ distance</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DTW distance</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Frechet distance</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>$d_Q$ distance</td>\n",
              "      <td>0.2843</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.4583</td>\n",
              "      <td>0.0524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Distance  Train Error  ...  Median Error  Standar Deviation\n",
              "1  $d_Q^{\\sigma}$ distance       0.0000  ...        0.0000             0.0000\n",
              "2             DTW distance       0.0000  ...        0.0000             0.0000\n",
              "3         Frechet distance       0.0000  ...        0.0000             0.0000\n",
              "4           $d_Q$ distance       0.2843  ...        0.4583             0.0524\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPLa-pnxIata",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9d54f964-f1af-444d-f1b2-fd6de2904115"
      },
      "source": [
        "E4 = df4.to_latex(index=False)\n",
        "np.savetxt('table-KNN.tex', [E4], fmt='%s')\n",
        "files.download('table-KNN.tex')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ed68cf25-1652-44dc-aed6-0b625235860f\", \"table-KNN.tex\", 576)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}